{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SETTING UP THE SPARK SESSION**"
      ],
      "metadata": {
        "id": "f-trNI1znmAc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1CNFJXxaywE",
        "outputId": "64ba7cf4-0079-4f2b-9f23-bde54ed2109e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=c3f77319eeae134e490f7e6e29ad7dafc56ecceebe89ef83473f59e48fdf9ca9\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, max, min, avg, count, countDistinct, lit, sum, when, year, month, dayofmonth, stddev, expr, first, row_number\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import DateType\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Weather Data Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print('Spark Session Initialized')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPJJ_AgRcu0d",
        "outputId": "c34c103c-c2eb-43d7-a26a-20fc2f69eeb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Session Initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file assuming the data.zip is in the same directory as this ipynb file\n",
        "zip_file_path = 'data.zip'\n",
        "\n",
        "# Directory where the zip file will be extracted\n",
        "extract_to_dir = 'data'\n",
        "\n",
        "# Check if the extraction directory exists, create if it doesn't\n",
        "if not os.path.exists(extract_to_dir):\n",
        "    os.makedirs(extract_to_dir)\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the contents into the directory\n",
        "    zip_ref.extractall(extract_to_dir)\n",
        "\n",
        "print(f\"Extracted all files in {zip_file_path} to {extract_to_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S78kIm1ReMhy",
        "outputId": "69f79e76-5645-47c0-801c-e3936524beff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all files in data.zip to data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the data.zip has been extracted into a folder named 'data'\n",
        "weather_df = spark.read.csv(\"data/data/*/*.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "S24UlEdReQA-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out missing values and add a column for the year\n",
        "filtered_weather_df = weather_df.filter(\n",
        "    (weather_df[\"MAX\"] != 9999.9) &\n",
        "    (weather_df[\"MIN\"] != 9999.9) &\n",
        "    (weather_df[\"PRCP\"] != 99.99) &\n",
        "    (weather_df[\"TEMP\"] != 9999.9)\n",
        ").withColumn(\"YEAR\", year(\"DATE\"))"
      ],
      "metadata": {
        "id": "HoN4C8fxegzg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 1**\n",
        "\n",
        "Finding the hottest day (column MAX) for each year, and providing the corresponding station code, station name and the date (columns STATION, NAME, DATE)"
      ],
      "metadata": {
        "id": "Ywnh8YrnUiW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a window partitioned by year and ordered by maximum temperature\n",
        "window_spec = Window.partitionBy(\"YEAR\").orderBy(filtered_weather_df[\"MAX\"].desc())\n",
        "\n",
        "# Adding a row number column to identify the row with maximum temperature for each year\n",
        "max_temps_per_year = filtered_weather_df.withColumn(\"row_number\", row_number().over(window_spec)) \\\n",
        "    .where(col(\"row_number\") == 1) \\\n",
        "    .drop(\"row_number\")\n",
        "\n",
        "# Selecting columns in the desired order\n",
        "max_temps_per_year.select(\"STATION\", \"NAME\", \"DATE\", \"MAX\").orderBy(\"DATE\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNwa5wYK1eIN",
        "outputId": "10ac4bee-ab50-434d-9ad6-79be086a8be1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+----------+----+\n",
            "|    STATION|                NAME|      DATE| MAX|\n",
            "+-----------+--------------------+----------+----+\n",
            "| 2095099999|          PAJALA, SW|2022-07-01|85.5|\n",
            "| 1065099999|        KARASJOK, NO|2021-07-05|88.3|\n",
            "| 1023099999|       BARDUFOSS, NO|2020-06-22|79.9|\n",
            "| 1023099999|       BARDUFOSS, NO|2019-07-21|78.8|\n",
            "| 1025099999|          TROMSO, NO|2018-07-29|84.2|\n",
            "| 1023099999|       BARDUFOSS, NO|2017-06-09|78.6|\n",
            "| 1023199999|         DRAUGEN, NO|2016-07-21|77.0|\n",
            "| 1025099999|          TROMSO, NO|2015-07-30|71.6|\n",
            "| 1023099999|       BARDUFOSS, NO|2014-07-10|89.6|\n",
            "| 1001499999|      SORSTOKKEN, NO|2013-08-02|80.6|\n",
            "| 1023099999|       BARDUFOSS, NO|2012-07-05|72.0|\n",
            "| 1046099999|       SORKJOSEN, NO|2011-07-09|87.8|\n",
            "|99407099999|DESTRUCTION IS. W...|2010-08-15|74.8|\n",
            "+-----------+--------------------+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 2**\n",
        "\n",
        "Finding the coldest day (column MIN) for the month of January across all years (2010 - 2022), and providing the corresponding station code, station name and the date (columns STATION, NAME, DATE)."
      ],
      "metadata": {
        "id": "nvvXm9C6U3XS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the coldest day in January\n",
        "coldest_january = filtered_weather_df.withColumn(\"MONTH\", month(\"DATE\")) \\\n",
        "    .filter(col(\"MONTH\") == 1) \\\n",
        "    .select(\"STATION\", \"NAME\", \"DATE\", \"MIN\") \\\n",
        "    .orderBy(\"MIN\").limit(1)\n",
        "\n",
        "coldest_january.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3xNtmB3glAs",
        "outputId": "5ec4f467-3a17-4e25-f828-dd7776345ab6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+----------+-----+\n",
            "|   STATION|         NAME|      DATE|  MIN|\n",
            "+----------+-------------+----------+-----+\n",
            "|1023099999|BARDUFOSS, NO|2017-01-05|-28.3|\n",
            "+----------+-------------+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 3**\n",
        "\n",
        "Finding the maximum and minimum precipitation (column PRCP) for the year 2015, and providing the corresponding station code, station name and the date (columns STATION, NAME, DATE)."
      ],
      "metadata": {
        "id": "-_VuygHmVmYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_2015 = filtered_weather_df.filter(col(\"YEAR\") == 2015)\n",
        "\n",
        "# Calculate maximum and minimum precipitation for the year 2015\n",
        "max_precipitation = weather_2015.agg(max(\"PRCP\").alias(\"MAX_PRCP\")).collect()[0][\"MAX_PRCP\"]\n",
        "min_precipitation = weather_2015.agg(min(\"PRCP\").alias(\"MIN_PRCP\")).collect()[0][\"MIN_PRCP\"]\n",
        "\n",
        "# Find corresponding station code, station name, and date for maximum precipitation\n",
        "max_precipitation_data = weather_2015.filter(col(\"PRCP\") == max_precipitation).select(\"STATION\", \"NAME\", \"DATE\", \"PRCP\")\n",
        "\n",
        "# Find corresponding station code, station name, and date for minimum precipitation\n",
        "min_precipitation_data = weather_2015.filter(col(\"PRCP\") == min_precipitation).select(\"STATION\", \"NAME\", \"DATE\", \"PRCP\").limit(1)\n",
        "\n",
        "# Show the results\n",
        "print(\"Maximum Precipitation for 2015:\")\n",
        "max_precipitation_data.show()\n",
        "\n",
        "print(\"Minimum Precipitation for 2015:\")\n",
        "min_precipitation_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQPOxYf8hvbP",
        "outputId": "b639aa81-c36b-4ec2-e9c9-7a3708448ad5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Precipitation for 2015:\n",
            "+----------+----------+----------+----+\n",
            "|   STATION|      NAME|      DATE|PRCP|\n",
            "+----------+----------+----------+----+\n",
            "|1025099999|TROMSO, NO|2015-11-02|2.11|\n",
            "+----------+----------+----------+----+\n",
            "\n",
            "Minimum Precipitation for 2015:\n",
            "+----------+------------+----------+----+\n",
            "|   STATION|        NAME|      DATE|PRCP|\n",
            "+----------+------------+----------+----+\n",
            "|1008099999|LONGYEAR, SV|2015-01-01| 0.0|\n",
            "+----------+------------+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 4**\n",
        "\n",
        "Counting the percentage of missing values for wind gust (column GUST) for the year 2019."
      ],
      "metadata": {
        "id": "XRV0kE1gY0bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of missing gust data for the year 2019\n",
        "gust_missing_2019 = weather_df.filter(year(\"DATE\") == 2019) \\\n",
        "    .select((count(when(col(\"GUST\") == 999.9, True)) / count(\"*\") * 100).alias(\"MISSING GUST PERCENTAGE\"))\n",
        "\n",
        "gust_missing_2019.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAj6e-ztjDoA",
        "outputId": "b9be59ec-ae23-47bb-a136-5e33b57cbde8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+\n",
            "|MISSING GUST PERCENTAGE|\n",
            "+-----------------------+\n",
            "|      82.87671232876713|\n",
            "+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 5**\n",
        "\n",
        "Finding the mean, median, mode and standard deviation of the temperature (column TEMP) for each month for the year 2020."
      ],
      "metadata": {
        "id": "ZZIbkkB3ax1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_2020 = filtered_weather_df.filter(year(\"DATE\") == 2020)\n",
        "\n",
        "# Extract month from the date\n",
        "weather_2020 = weather_2020.withColumn(\"Month\", month(\"DATE\"))\n",
        "\n",
        "# Calculate mean, median, mode, and standard deviation for each month\n",
        "monthly_stats_2020 = weather_2020.groupBy(\"Month\") \\\n",
        "    .agg(avg(\"TEMP\").alias(\"Mean TEMP\"),\n",
        "         expr(\"percentile_approx(TEMP, 0.5)\").alias(\"Median TEMP\"),\n",
        "         expr(\"sort_array(collect_list(TEMP))[(cast(size(collect_list(TEMP)) as int) + 1) DIV 2]\").alias(\"Mode TEMP\"),\n",
        "         stddev(\"TEMP\").alias(\"Stddev TEMP\")) \\\n",
        "    .orderBy(\"Month\")\n",
        "\n",
        "monthly_stats_2020.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plmOTtmsjqup",
        "outputId": "be3ff5c0-7971-4379-aedf-c7c64e75253e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------+-----------+---------+------------------+\n",
            "|Month|         Mean TEMP|Median TEMP|Mode TEMP|       Stddev TEMP|\n",
            "+-----+------------------+-----------+---------+------------------+\n",
            "|    1|15.210169491525424|       14.7|     14.9|12.653031460610185|\n",
            "|    2|13.577358490566038|       15.3|     15.5|13.186832615404859|\n",
            "|    3|15.023333333333335|       18.6|     19.9|15.829465837499535|\n",
            "|    4|23.329999999999995|       26.0|     28.6|13.022097256170087|\n",
            "|    5| 36.21935483870968|       36.0|     36.1| 8.077246704851957|\n",
            "|    6|47.429999999999986|       46.0|     46.2| 8.877190347997288|\n",
            "|    7| 52.88709677419355|       51.4|     51.7| 6.663787232915164|\n",
            "|    8|49.376666666666665|       48.7|     49.0| 6.615066692379813|\n",
            "|    9| 40.92727272727273|       39.0|     43.0| 8.161138512375697|\n",
            "|   10|29.690322580645162|       24.3|     25.2|10.800072679962533|\n",
            "|   11|             31.01|       29.8|     30.4| 7.744883615795801|\n",
            "|   12|18.642857142857142|       19.5|     20.1| 9.619956934860543|\n",
            "+-----+------------------+-----------+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRINTING ALL THE DESIRED OUTPUT TO \"result.txt\"**"
      ],
      "metadata": {
        "id": "Jt22z_Szn6bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "max_temps_per_year_df = max_temps_per_year.select(\"STATION\", \"NAME\", \"DATE\", \"MAX\").orderBy(\"DATE\", ascending=False)\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "max_temps_per_year_pd = max_temps_per_year_df.toPandas()\n",
        "coldest_january_pd = coldest_january.toPandas()\n",
        "max_precipitation_data_pd = max_precipitation_data.toPandas()\n",
        "min_precipitation_data_pd = min_precipitation_data.toPandas()\n",
        "gust_missing_2019_pd = gust_missing_2019.toPandas()\n",
        "monthly_stats_2020_pd = monthly_stats_2020.toPandas()\n",
        "\n",
        "# Define the file path\n",
        "file_path = \"/result.txt\"\n",
        "\n",
        "# Formatting the output file\n",
        "with open(file_path, \"w\") as f:\n",
        "    f.write(\"TASK 1:\\n\")\n",
        "    f.write(\"The hottest day for each year.\\n\")\n",
        "    f.write(tabulate(max_temps_per_year_pd, headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "    f.write(\"\\n\\nTASK 2:\\n\")\n",
        "    f.write(\"The coldest day for the month of January across all years.\\n\")\n",
        "    f.write(tabulate(coldest_january_pd, headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "    f.write(\"\\n\\nTASK 3:\\n\")\n",
        "    f.write(\"Maximum Precipitation for 2015.\\n\")\n",
        "    f.write(tabulate(max_precipitation_data_pd, headers='keys', tablefmt='psql', showindex=False))\n",
        "    f.write(\"\\nMinimum Precipitation for 2015.\\n\")\n",
        "    f.write(tabulate(min_precipitation_data_pd, headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "    f.write(\"\\n\\nTASK 4:\\n\")\n",
        "    f.write(\"Percentage of missing values for wind gust for the year 2019.\\n\")\n",
        "    f.write(tabulate(gust_missing_2019_pd, headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "    f.write(\"\\n\\nTASK 5:\\n\")\n",
        "    f.write(\"The mean, median, mode and standard deviation of the temperature for each month for the year 2020.\\n\")\n",
        "    f.write(tabulate(monthly_stats_2020_pd, headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "print(\"Data has been saved to: \", file_path)"
      ],
      "metadata": {
        "id": "9PzfyuDMc7C7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f8f4a4-6760-4c42-97c2-d43a4af278a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been saved to:  /result.txt\n"
          ]
        }
      ]
    }
  ]
}